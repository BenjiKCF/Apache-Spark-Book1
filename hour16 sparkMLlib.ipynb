{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stunning-marsh",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fitting-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sought-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = data.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "satisfactory-sheriff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indirect-continent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-thursday",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "falling-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "outlook = {\"sunny\": 0.0, \"overcast\": 1.0, \"rainy\": 2.0}\n",
    "\n",
    "labeledpoints = [\n",
    "    LabeledPoint(0.0, [outlook[\"sunny\"],85,85,False]),\n",
    "    LabeledPoint(0.0, [outlook[\"sunny\"],80,90,True]),\n",
    "    LabeledPoint(1.0, [outlook[\"overcast\"],83,86,False]),\n",
    "    LabeledPoint(1.0, [outlook[\"rainy\"],70,96,False]),\n",
    "    LabeledPoint(1.0, [outlook[\"rainy\"],68,80,False]),\n",
    "    LabeledPoint(0.0, [outlook[\"rainy\"],65,70,True]),\n",
    "    LabeledPoint(1.0, [outlook[\"overcast\"],64,65,True]),\n",
    "    LabeledPoint(0.0, [outlook[\"sunny\"],72,95,False]),\n",
    "    LabeledPoint(1.0, [outlook[\"sunny\"],69,70,False]),\n",
    "    LabeledPoint(1.0, [outlook[\"sunny\"],75,80,False]),\n",
    "    LabeledPoint(1.0, [outlook[\"sunny\"],75,70,True]),\n",
    "    LabeledPoint(1.0, [outlook[\"overcast\"],72,90,True]),\n",
    "    LabeledPoint(1.0, [outlook[\"overcast\"],81,75,False]),\n",
    "    LabeledPoint(0.0, [outlook[\"rainy\"],71,91,True])]\n",
    "\n",
    "data = sc.parallelize(labeledpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "retained-columbus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,85.0,85.0,0.0]),\n",
       " LabeledPoint(0.0, [0.0,80.0,90.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,83.0,86.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,70.0,96.0,0.0]),\n",
       " LabeledPoint(1.0, [2.0,68.0,80.0,0.0]),\n",
       " LabeledPoint(0.0, [2.0,65.0,70.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,64.0,65.0,1.0]),\n",
       " LabeledPoint(0.0, [0.0,72.0,95.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,69.0,70.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,75.0,80.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,75.0,70.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,72.0,90.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,81.0,75.0,0.0]),\n",
       " LabeledPoint(0.0, [2.0,71.0,91.0,1.0])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "italic-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-tattoo",
   "metadata": {},
   "source": [
    "The categoricalFeaturesInfo argument is a dict or map that specifies which features are categorical and how many categorical values each of those features can take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "governmental-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree.trainClassifier(data=data,\n",
    "        numClasses=2,\n",
    "        categoricalFeaturesInfo={0: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ranging-thriller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 3 with 9 nodes\n",
      "  If (feature 0 in {0.0,2.0})\n",
      "   If (feature 2 <= 82.5)\n",
      "    If (feature 1 <= 66.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 1 > 66.5)\n",
      "     Predict: 1.0\n",
      "   Else (feature 2 > 82.5)\n",
      "    If (feature 1 <= 70.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 1 > 70.5)\n",
      "     Predict: 0.0\n",
      "  Else (feature 0 not in {0.0,2.0})\n",
      "   Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "limited-intervention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([1.0,85,85,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-lucas",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "wrapped-donna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "\n",
    "model = NaiveBayes.train(data=data, lambda_ = 1.0)\n",
    "model.predict([1.0, 85,85,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-blake",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fantastic-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "preceding-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile('movielens.dat')\n",
    "ratings = data.map(lambda x: x.split('\\t'))\\\n",
    "    .map( lambda x: Rating(int(x[0]), int(x[1]), float(x[2]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "colored-output",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=196, product=242, rating=3.0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "reported-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "elect-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = ratings.map(lambda p: (p[0], p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "broke-chapel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(196, 242), (186, 302)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "supreme-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predictAll(testdata).map(lambda r: ( (r[0], r[1]), r[2]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "romantic-memory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((316, 1084), 3.916170460277161), ((504, 1084), 3.768507462239329)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "jewish-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "informed-horse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((186, 302), (3.0, 2.609181678937813)),\n",
       " ((115, 265), (2.0, 3.035589378218772))]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratesAndPreds.take(2) #label, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "honey-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "compound-retirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.4822655821612374\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-communication",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#â€œmodel.save(sc, \"file:///opt/spark/data/ratings_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "# reloaded_model = MatrixFactorizationModel.load(sc, \"file:///opt/spark/data/ratings_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-driving",
   "metadata": {},
   "source": [
    "# Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dental-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel #Numpy\n",
    "from numpy import array\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "billion-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "data = sc.textFile(\"/usr/local/Cellar/apache-spark/3.0.1/libexec/data/mllib/kmeans_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "banned-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n",
    "\n",
    "clusters = KMeans.train(parsedData, 2, maxIterations=10, initializationMode='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "broke-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate clustering by computing Within Set Sum of Squared Errors\n",
    "\n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sqrt(sum([x**2 for x in (point - center)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "rough-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within set sum of squared error = 0.6928203230275529\n"
     ]
    }
   ],
   "source": [
    "WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x,y: x+y)\n",
    "print(\"Within set sum of squared error = \"+str(WSSSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-start",
   "metadata": {},
   "source": [
    "# Save and load kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "casual-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters.save(sc, \"hdfs:///.../kmeans_model\")\n",
    "# reloaded_model = KMeansModel.load(sc, \"hdfs:///.../kmeans_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-newman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-russia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-terrain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-stereo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
